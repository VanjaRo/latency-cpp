# Latency Spring 2025

## Описание задачи

Подробное описание будет дано на вступительной лекции. Здесь приведены лишь основные моменты, а также ряд технических деталей, не покрытых в лекции.

В рамках соревнования вам нужно написать программу, которая получает данные по ордербукам по многим инструментам и поддерживает корректные ордербуки по заданному заранее подмножеству инструментов. В ордербуке необходимо корректно поддерживать первые 5 уровней. Обозначим уровни цен для асков как $p_1^a, p_2^a, ..., p_5^a$ и аналогично для бидов $p_i^b$. Обозначим также объемы, на соответствующих уровнях как $q_1^a, ..., q_5^a$. Вам необходимо подсчитывать _имбаланс_, считаемый как
```math
Imb = \frac{\sum_{i=0}^{5} q_i^b - \sum_{i=0}^5 q_i^a}{\sum_{i=0}^5 q_i^b + \sum_{i=0}^5 q_i^a} 
```

## Формат данных

### Сетевой стек

Входные данные подаются в виде udp трафика, записанного в pcap файлах. Исходный протокол используется на реальных биржах, но был немного изменен для целей данного соревнования. Также в рамках проекта ряд полей в данных были изменены (ip и mac адреса, названия инструментов и т.д.). В остальном же данные максимально близки к записи сырого сетевого трафика.

Каждый udp пакет содержит только один eth фрейм. Каждый фрейм в данных содержит информацию с обновлениями ордербуков по одному или нескольким инструментам. Помимо этого встречаются и данные других типов, но в рамках этого проекта их можно пропускать.

Поскольку разных инструментов в данных много (несколько тысяч), то обновления ордербуков по всем могут занимать много фреймов. Однако, **гарантируется, что в рамках одного фрейма для каждого инструмента в этом фрейме
содержится полное обновление ордербука**. Иными словами, после обработки каждого фрейма все ордербуки находятся в валидном состоянии.

### Протокол данных

Здесь описан непосредственно протокол кодирования данных (т.е. содержимое udp payload, т.е. Application Layer). В описании помимо понятных названий типов вроде int32 или uint32 будет встречаться vint. Последний представляет собой схему кодирования знаковых 64-битных чисел, используя переменное число байт (от 1 до 10).

vint сначала кодирует число в беззнаковое 64-битное с помощью ZigZag, а затем полученное беззнаковое число кодируется с помощью varint. В целом, vint совпадает с sint64 из Google Protocol Buffers, его описание может быть найдено здесь: https://protobuf.dev/programming-guides/encoding/.

Таким образом, для декодирования vint нужно сделать все в обратном порядке:
- декодировать varint, описание которого можно найти здесь: https://protobuf.dev/programming-guides/encoding/#varints
- декодировать ZigZag, описание которого можно найти здесь: https://protobuf.dev/programming-guides/encoding/#signed-ints

**Все числа в протоколе записаны в little-endian. Выравнивание не используется ни для каких полей.**

Также в типах встречается `char[n]`. Данный тип кодирует 0-terminated строку длиной не более `n-1` (т.е. тип занимает ровно `n` байт, чтобы прочитать строку, нужно читать до первого нулевого байта).

#### Структура данных

Каждый фрейм может содержать один или более пакет с данными ("пакет" в Application Layer).

Каждый пакет с данными состоит из хедера и следующего непосредственно за ним содержимого пакета. Хедер задает описание пакета и представляет собой набор типизированных записей. В начале всегда следуют следующие 3 записи:
- `uint8 flag`
- `uintp typeid` - тип сообщения, по нему можно определить сообщение какого типа далее следует.
- `uint16 length` - длина сообщения (без учета хедера). Можно использовать, чтобы понимать, где заканчивается очередной пакет (например, если его нужно просто пропустить).

В рамках проекта нас интересуют только сообщениях двух типов: снепшоты (`typeid=0x32`) и инкрементальные апдейты
(`typeid=0x01`).

Содержимое пакета после хедера представляет собой последовательность _полей_. Каждое _поле_ также состоит из хедера и содержимого поля. Хедер любого поля состоит из 2 чисел:
- `uint16 field_id` - задает тип поля
- `uint16 field_len` - длина содержимого поля

Содержимое поля представляет собой последовательность типизированных записей (как в хедере) и зависит от типа поля.

#### Снепшоты (typeid=0x32)

Снепшот содержит большое количество полей, однако большая их часть в рамках проекта нам не интересна. Для таких полей указано только field_id и field_size, чтобы их можно было пропустить. Поля следуют в таком порядке:
- `field_id=0x0032, field_size=9` (может быть несколько таких полей или 0)
- `field_id=0x0031, field_size=22`
- `field_id=0x1001, field_size=6` 
- `field_id=0x1003, field_size=37`
- `field_id=0x1002, field_size=22`
- Incremental packet field (`field_id=0x1004`). Включает в себя:
  - `int32 packet_no` - номер последнего инкрементального апдейта в снепшоте. Фактически означает, что в данный снепшот уже включены все апдейты с номерами не больше заданного (используется при мерже снепшотов и апдейтов, описано далее).
- Instrument information field (`field_id=0x0101`). Содержит общую информацию об инструменте, включает в себя:
  - `char[31] intrument_id` - текстовое название инструмента.
  - 61 байт, с информацией, которая нам не нужна
  - `double tick_size` - любая цена для этого инструмента должна быть множителем tick_size.
  - `double reference_price` - базовая цена, от которой отсчитываются смещения в инкрементальных апдейтах.
  - `int32 instrument_no` - код инструмента, который в дальнейшем используется в апдейтах для идентификации инструмента.
- `field_id=0x0102, field_size=154`
- Непосредственно содержимое ордербука (`field_id=0x0103`). Состоит из не более, чем 2N записей следующего вида:
  - `int32 instrument_no` - номер инструмента, совпадает с таковым в information field.
  - `char direction` - '0' для бидов и '1' для асков.
  - `double price` - уровень цены (абсолютный)
  - `int32 volume` - объем на данной цене.

#### Инкрементальные апдейты (typeid=0x01)

Каждый апдейт содержит поле с хедером, какое-то количество полей с непосредственно обновлениями ордербука (может быть и нулевое), а также может содержать summary-поля, которые нас не интересуют.

Поле с хедером (`field_id=0x0003`) содержит:
- `vint instrument_no` - код инструмента, по которому идут дальнейшие поля в рамках этого апдейта
- `vint change_no` - номер инкремента, используется для корректного мержа снепшотов и апдейтов (описано далее)

Непосредственно поле с обновлениями (`field_id=0x1001`) содержит:
- `char event_type`. '1' при добавлении нового уровня, '2' при изменении существующего, '3' при удалении уровня.
- `char md_entry_type`. '0' если это обновление бидов, '1' если асков.
- `vint price_level`. Номер уровня цены (индексация с 1), где необходимо применить изменение.
- `vint price_offset`. Непосредственно уровень цены. Задается как прибавка, которую нужно добавить к reference price из снепшота для текущего инструмента. Т.е. если данное значение равно `n`, то реальный уровень цены равен `reference + n * tick_size`.
- `vint volume` - объем на данном уровне цены.

**Обратите внимание на следующие особенности:**
1. В процессе применения индивидуальных обновлений (с `field_id=0x1001`) ордербук может находиться в некорректном состоянии. Его корректность гарантируется только по завершению всего апдейта.
2. Несмотря на то, что нас интересуют только первые 5 уровней ордербука (и только информация по ним будет во входных данных), необходимо поддерживать ордербук и дальше этой глубины, т.к. более глубокие уровни могут войти в первые 5 в случае удалений например.

summary-поля включают в себя поля с field_id из списка (0x1002, 0x1011, 0x1012, 0x1013, 0x1014, 0x1015, 0x1016). Каждый field_id может встречаться не более 1 раза в рамках апдейта.

### Как правильно поддерживать ордербук

Ордербуки по разным инструментам независимы друг от друга. В общем алгоритм состоит в последовальном чтении снепшотов и апдейтов, и применении апдейтов поверх текущего состояния ордербука. Особенность состоит в том, что иногда необходимо восстанавливать ордербук из снепшота заново (например, в начале считывания данных, при потере каких-то апдейтов или же просто при получении нового снепшота).

Для синхронизации снепшотов и апдейтов используюся поля `packet_no` в снепшоте и `change_no` в апдейтах. При применении апдейтов если очередной `change_no` не равен предыдущему+1, то необходимо пропустить все апдейты до следующего снепшота (фактически, часть данных была потеряна).

После применения снепшота применять апдейты к нему стоит начинать только когда `change_no = packet_no + 1`.

## Основные части окружения

Окружение проекта включает в себя:
- сырые данные
- ваше решение
- бинарь (runner), взаимодействующий с вашим решением. runner запускает решение как дочерний процесс, читает данные из pcap файлов и подает их на вход в shared memory, а также вычитывает вывод решения из shared memory. Также производит замеры времени.

runner не имеет никаких динамических зависимостей и может быть запущен на любой достаточно свежей linux-системе. Если в вашем случае это не так, то вы можете использовать докер для запуска, достаточно образа с `ubuntu:22.04` или новее. В случае запуска в докере крайне рекомендуется использовать флаг `--ipc=host`.

## Формат решения

### Формат ввода-вывода

Общение между runner и решением происходит с помощью двух single-producer-single-consumer очередей. Каждая очередь задается двумя файлами в /dev/shm: хедером и буфером. Формат хедера может быть описан следующим образом:

```c++
struct spsc_header_t {
    alignas(64) std::atomic<uint32_t> producer_offset;
    alignas(64) std::atomic<uint32_t> consumer_offset;
};
```

Т.е. хедер ключает в себя текущие оффсеты писателя и читателя в буфере, выровненные по границе 64 байт.
Буфер размера `N` байт (этот размер передается в решение отдельно) представляет собой в реальности файл размера `2N` в shared memory. Это сделано для того, чтобы можно было удобно закольцевать данные в буфере.

При запуске решения runner сам создаст нужные файлы и проинициализирует оффсеты в 0. Протокол общения устроен следующим образом (пусть размер буфера равен `N` как в примере выше):

- для записи `k` байт producer берет текущий producer_offset по модулю `N`, после чего пишет `k` байт, начиная с данной позиции. По завершению producer_offset увеличивается на `k`.
- для чтения consumer берет текущий consumer_offset и сравнивает с producer_offset. Если последний больше на `t` байт, это означает, что с `consumer_offset % N` можно прочитать `t` байт. По завершению чтения consumer_offset должен быть увеличен на `t`.

Гарантируется, что `N` это всегда степень двойки. Также обратите внимание, что оффсеты в хедере хранятся в абсолютном значении, взятие по модулю производится уже непосредственно при чтении/записи в буфер. За счет того, что `N` всегда является степенью двойки, переполнения `uint32_t` тут не влияют на корректность.

### Работа с pcap файлами

Для просмотра данных в pcap файлах лучше всего подходит Wireshark. У него есть консольный аналог tshark, но последний не очень удобен для интерактивной работы с данными. Промежуточным вариантом между двумя является termshark (https://github.com/gcla/termshark), который предоставляет консольный интерфейс.

Для упрощения дебага перед взаимодействием с раннером рекомендуется отладить свое решение, напрямую работая с pcap файлами. Для чтения pcap из C++ можно использовать одну из двух библиотек:
- libpcap (и пример использования https://elf11.github.io/2017/01/22/libpcap-in-C.html)
- LightPcapNg (https://github.com/rvelea/LightPcapNg и пример использования в тестах https://github.com/rvelea/LightPcapNg/blob/master/src/tests/test_read_packets.c)

### Требования к решению

В вашем репозитории должен находиться скрипт `build.sh`, который запускает сборку. По итогу должен быть создан бинарь `solution`, который должен удовлетворять требованиям, описанным выше.

## Как устроено тестирование на сервере

- Машина для тестирования:
- Тактовая частота:
- TSc_MZ
- hyper-threading отключен

Параллельно на сервере может быть запущено не более, чем 4 решения. Каждое решение запускается на своем подмножестве изолированных ядер. Помимо этого L3 кеш поделен на 5 равных частей с помощью resctrl (4 для решений и 1 для самой системы), т.е. каждому решению доступно ~9MB L3 кеша.
