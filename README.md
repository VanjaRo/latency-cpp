# Latency Spring 2025

## Описание задачи

Подробное описание будет дано на вступительной лекции. Здесь приведены лишь основные моменты, а также ряд технических деталей, не покрытых в лекции.

В рамках соревнования вам нужно написать программу, которая получает данные по ордербукам по многим инструментам и поддерживает корректные ордербуки по заданному заранее подмножеству инструментов. В ордербуке необходимо корректно поддерживать первые 5 **ненулевых** уровней. Обозначим уровни цен для асков как $p_1^a, p_2^a, ..., p_5^a$ и аналогично для бидов $p_i^b$. Обозначим также объемы, на соответствующих уровнях как $q_1^a, ..., q_5^a$. Вам необходимо подсчитывать _имбаланс_, считаемый как
```math
Imb = \frac{\sum_{i=0}^{5} q_i^b - \sum_{i=0}^5 q_i^a}{\sum_{i=0}^5 q_i^b + \sum_{i=0}^5 q_i^a} 
```

Обратите внимание, что в реальности имбаланс считается обычно в том числе и по нулевым уровням. 

## Формат данных

### Сетевой стек

Входные данные подаются в виде udp трафика, записанного в pcap файлах. Исходный протокол используется на реальных биржах, но был немного изменен для целей данного соревнования. Также в рамках проекта ряд полей в данных были изменены (ip и mac адреса, названия инструментов и т.д.). В остальном же данные максимально близки к записи сырого сетевого трафика.

Каждый udp пакет содержит только один eth фрейм. Каждый фрейм в данных содержит информацию с обновлениями ордербуков по одному или нескольким инструментам. Помимо этого встречаются и данные других типов, но в рамках этого проекта их можно пропускать.

Поскольку разных инструментов в данных много (несколько тысяч), то обновления ордербуков по всем могут занимать много фреймов. Однако, **гарантируется, что в рамках одного фрейма для каждого инструмента в этом фрейме
содержится полное обновление ордербука**. Иными словами, после обработки каждого фрейма все ордербуки находятся в валидном состоянии.

### Протокол данных

Здесь описан непосредственно протокол кодирования данных (т.е. содержимое udp payload, т.е. Application Layer). В описании помимо понятных названий типов вроде int32 или uint32 будет встречаться vint. Последний представляет собой схему кодирования знаковых 64-битных чисел, используя переменное число байт (от 1 до 10).

vint сначала кодирует число в беззнаковое 64-битное с помощью ZigZag, а затем полученное беззнаковое число кодируется с помощью varint. В целом, vint совпадает с sint64 из Google Protocol Buffers, его описание может быть найдено здесь: https://protobuf.dev/programming-guides/encoding/.

Таким образом, для декодирования vint нужно сделать все в обратном порядке:
- декодировать varint, описание которого можно найти здесь: https://protobuf.dev/programming-guides/encoding/#varints
- декодировать ZigZag, описание которого можно найти здесь: https://protobuf.dev/programming-guides/encoding/#signed-ints

**Все числа в протоколе записаны в little-endian. Выравнивание не используется ни для каких полей.**

Также в типах встречается `char[n]`. Данный тип кодирует 0-terminated строку длиной не более `n-1` (т.е. тип занимает ровно `n` байт, чтобы прочитать строку, нужно читать до первого нулевого байта).

#### Структура данных

Каждый фрейм может содержать один или более пакет с данными ("пакет" в Application Layer).

Каждый пакет с данными состоит из хедера и следующего непосредственно за ним содержимого пакета. Хедер задает описание пакета и представляет собой набор типизированных записей. В начале всегда следуют следующие 3 записи:
- `uint8 dummy` - в рамках проекта нас не интересует
- `uint8 typeid` - тип сообщения, по нему можно определить сообщение какого типа далее следует.
- `uint16 length` - длина сообщения (без учета хедера).

В рамках проекта нас интересуют только сообщениях двух типов: снепшоты (`typeid=0x32`) и инкрементальные апдейты
(`typeid=0x01`). В обоих случаях хедеры содержат дополнительные записи, которые тут не описаны. В случае снепшота хедер включает в себя еще 4 байта, а в случае апдейта еще 20 байт.

Содержимое пакета после хедера представляет собой последовательность _полей_. Каждое _поле_ также состоит из хедера и содержимого поля. Хедер любого поля состоит из 2 чисел:
- `uint16 field_id` - задает тип поля
- `uint16 field_len` - длина содержимого поля

Содержимое поля представляет собой последовательность типизированных записей (как в хедере) и зависит от типа поля.

#### Снепшоты (typeid=0x32)

Снепшот содержит большое количество полей, однако большая их часть в рамках проекта нам не интересна. Для таких полей указано только field_id и field_size, чтобы их можно было пропустить. Поля следуют в таком порядке:
- `field_id=0x0032, field_size=9` (может быть несколько таких полей или 0)
- `field_id=0x0031, field_size=22`
- `field_id=0x1001, field_size=6` 
- `field_id=0x1003, field_size=37`
- `field_id=0x1002, field_size=22`
- Incremental packet field (`field_id=0x1004`). Включает в себя:
  - `int32 packet_no` - номер последнего инкрементального апдейта в снепшоте. Фактически означает, что в данный снепшот уже включены все апдейты с номерами не больше заданного (используется при мерже снепшотов и апдейтов, описано далее).
- Далее следует ненулевое количество групп со следующими полями (фактически, каждая группа на инструмент):
  - Instrument information field (`field_id=0x0101`). Содержит общую информацию об инструменте, включает в себя:
    - `char[31] instrument_id` - текстовое название инструмента.
    - 61 байт, с информацией, которая нам не нужна
    - `double tick_size` - используется при расчете уровня цены в ордербуке (описано далее).
    - `double reference_price` - базовая цена, от которой отсчитываются смещения в инкрементальных апдейтах.
    - `int32 instrument_no` - код инструмента, который в дальнейшем используется в апдейтах для идентификации инструмента.
  - `field_id=0x0102, field_size=154`
  - Непосредственно содержимое ордербука (`field_id=0x0103`). Состоит из не более, чем 10 записей следующего вида:
    - `int32 instrument_no` - номер инструмента, совпадает с таковым в information field.
    - `char direction` - '0' для бидов и '1' для асков.
    - `double price` - уровень цены (абсолютный)
    - `int32 volume` - объем на данной цене.

#### Инкрементальные апдейты (typeid=0x01)

Каждый апдейт содержит ненулевое количество групп (каждая группа отвечает какому-то инструменту). Каждая группа включает в себя: поле с хедером, какое-то количество полей с непосредственно обновлениями ордербука (может быть и нулевое), а также может содержать summary-поля, которые нас не интересуют.

Поле с хедером (`field_id=0x0003`) содержит:
- `vint instrument_no` - код инструмента, по которому идут дальнейшие поля
- `vint change_no` - номер инкремента, используется для корректного мержа снепшотов и апдейтов (описано далее)

Непосредственно поле с обновлениями (`field_id=0x1001`) содержит:
- `char event_type`. '1' при добавлении нового уровня, '2' при изменении существующего, '3' при удалении уровня.
- `char md_entry_type`. '0' если это обновление бидов, '1' если асков.
- `vint price_level`. Номер уровня цены (индексация с 1), где необходимо применить изменение.
- `vint price_offset`. Непосредственно уровень цены. Задается как прибавка, которую нужно добавить к reference price из снепшота для текущего инструмента. Т.е. если данное значение равно `n`, то реальный уровень цены равен `reference + n * tick_size`.
- `vint volume` - объем на данном уровне цены.

**Обратите внимание на следующие особенности:**
1. В процессе применения индивидуальных обновлений (с `field_id=0x1001`) ордербук может находиться в некорректном состоянии. Его корректность гарантируется только по завершению всего апдейта.
2. Несмотря на то, что нас интересуют только первые 5 уровней ордербука (и только информация по ним будет во входных данных), необходимо поддерживать ордербук и дальше этой глубины, т.к. более глубокие уровни могут войти в первые 5 в случае удалений например.

summary-поля включают в себя поля с field_id из списка (0x1002, 0x1011, 0x1012, 0x1013, 0x1014, 0x1015, 0x1016). Каждый field_id может встречаться не более 1 раза в рамках каждой группы.

### Как правильно поддерживать ордербук

Ордербуки по разным инструментам независимы друг от друга. В общем алгоритм состоит в последовальном чтении снепшотов и апдейтов, и применении апдейтов поверх текущего состояния ордербука. Особенность состоит в том, что иногда необходимо восстанавливать ордербук из снепшота заново (например, в начале считывания данных, при потере каких-то апдейтов или же просто при получении нового снепшота).

Для синхронизации снепшотов и апдейтов используюся поля `packet_no` в снепшоте и `change_no` в апдейтах. При применении апдейтов если очередной `change_no` не равен предыдущему+1, то необходимо пропустить все апдейты до следующего снепшота (фактически, часть данных была потеряна).

После применения снепшота применять апдейты к нему стоит начинать только когда `change_no = packet_no + 1`.

## Основные части окружения

Окружение проекта включает в себя:
- сырые данные
- ваше решение
- бинарь (runner), взаимодействующий с вашим решением. runner запускает решение как дочерний процесс, читает данные из pcap файлов и подает их на вход в shared memory, а также вычитывает вывод решения из shared memory. Также производит замеры времени.

runner не имеет никаких динамических зависимостей и может быть запущен на любой достаточно свежей linux-системе. Если в вашем случае это не так, то вы можете использовать докер для запуска, достаточно образа с `ubuntu:22.04` или новее.

Раннер принимает следующие аргументы:
- `-sol` - путь до бинаря с решением
- `-meta` - путь до файла с метаданными (описано далее)
- `-b` - префикс, который стоит использовать при создании буферов в shared memory.
- `-sc` - (опциональный) номер ядра, куда запинить сам раннер.
- `-rc` - (опиональный) аналогично для решения. Ему предоставляется 2 ядра: rc и rc+1.
- `-disable-hugepages` - (опциональный) отключить использование hugepages для очередей в shared memory. Может пригодиться, если на вашей системе локально не включены hugepages.
- Оставшийся аргумент является путем до pcapng файла с данными.

Пример запуска:
```
./runner -b test_buffer -sol ./build/solution -meta public.meta public.pcapng 
```

В случае запуска в докере крайне рекомендуется использовать следующие флаги при запуске контейнера (mount нужен только если вы используете hugepages)
```
--ipc=host --mount type=bind,src=/dev/hugepages,dst=/dev/hugepages --ulimit memlock=-1`
```

## Формат решения

### Формат ввода-вывода

Общение между runner и решением происходит с помощью двух single-producer-single-consumer очередей. Каждая очередь задается двумя файлами в /dev/shm: хедером и буфером. Формат хедера может быть описан следующим образом:

```c++
struct spsc_header_t {
    alignas(64) std::atomic<uint32_t> producer_offset;
    alignas(64) std::atomic<uint32_t> consumer_offset;
};
```

Т.е. хедер ключает в себя текущие оффсеты писателя и читателя в буфере, выровненные по границе 64 байт.
Буфер размера `N` байт (этот размер передается в решение отдельно) представляет собой в реальности файл размера `2N` в shared memory. Это сделано для того, чтобы можно было удобно закольцевать данные в буфере.

При запуске решения runner сам создаст нужные файлы и проинициализирует оффсеты в 0. Протокол общения устроен следующим образом (пусть размер буфера равен `N` как в примере выше):

- для записи `k` байт producer берет текущий producer_offset по модулю `N`, после чего пишет `k` байт, начиная с данной позиции. По завершению producer_offset увеличивается на `k`.
- для чтения consumer берет текущий consumer_offset и сравнивает с producer_offset. Если последний больше на `t` байт, это означает, что с `consumer_offset % N` можно прочитать `t` байт. По завершению чтения consumer_offset должен быть увеличен на `t`.

Гарантируется, что `N` это всегда степень двойки. Также обратите внимание, что оффсеты в хедере хранятся в абсолютном значении, взятие по модулю производится уже непосредственно при чтении/записи в буфер. За счет того, что `N` всегда является степенью двойки, переполнения `uint32_t` тут не влияют на корректность.

### Работа с pcap файлами

Для просмотра данных в pcap файлах лучше всего подходит Wireshark. У него есть консольный аналог tshark, но последний не очень удобен для интерактивной работы с данными. Промежуточным вариантом между двумя является termshark (https://github.com/gcla/termshark), который предоставляет консольный интерфейс.

Для упрощения дебага перед взаимодействием с раннером рекомендуется отладить свое решение, напрямую работая с pcap файлами. Для чтения pcap из C++ можно использовать одну из двух библиотек:
- libpcap (и пример использования https://elf11.github.io/2017/01/22/libpcap-in-C.html)
- LightPcapNg (https://github.com/rvelea/LightPcapNg и пример использования в тестах https://github.com/rvelea/LightPcapNg/blob/master/src/tests/test_read_packets.c)

### Требования к решению

#### Что именно считать

В вашем репозитории должен находиться скрипт `build.sh`, который запускает сборку. По итогу должен быть создан бинарь `solution`, который должен быть запускаемым с помощью runner (т.к. именно так будет произодиться тестирование). Для этого он должен принимать следующие аргументы по порядку:
- имя хедера для входной очереди
- имя буфера для входной очереди
- имя хедера для выходной очереди
- имя буфера для выходной очереди
- размер обоих буферов (он одинаковый). Обратите внимание, что реальный размер в 2 раза больше указанного.
- путь до файла с метой

#### Метаданные

Файл с метой представляет собой текстовый файл следующего формата:
```
ip1 ip2
instrument1 threshold1
instrument2 threshold2
...
```

## Как устроено тестирование и замер результатов

- Машина для тестирования: Intel Xeon Gold 5412U
- Тактовая частота: 2900MHz
- TSC_MZ: 2100MHz
- hyper-threading отключен

Параллельно на сервере может быть запущено не более, чем 4 решения. Каждое решение запускается на своем подмножестве изолированных ядер. Помимо этого L3 кеш поделен на 5 равных частей с помощью resctrl (4 для решений и 1 для самой системы), т.е. каждому решению доступно ~9MB L3 кеша.

Запуск устроен следующим образом:
- раннер вычитывает фрейм из pcap файла и подает на вход решению
- таймер запускается непосредственно перед сдвигом оффсета в очереди раннер->решение
- таймер останавливается при получении новых данных в очереди решение->раннер
- таким образом раннер подает следующий фрейм только при получении ответ на текущий.

В качестве "таймера" используется https://en.wikipedia.org/wiki/Time_Stamp_Counter, мы замеряем непосредственно тики, без перевода в секунды.
